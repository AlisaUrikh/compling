{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SHpgueowsRdE",
        "JuKGl61csUO-"
      ],
      "authorship_tag": "ABX9TyMRL3hpmbUX6p6uTsvB+lRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/compling/blob/main/attention_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Курс \"Компьютерная лингвистика\" | НИУ ВШЭ Санкт-Петербург 2024 (c) В.И. Фирсанова`"
      ],
      "metadata": {
        "id": "jmhPIXaBmbxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эксперимент [Bahdanau et al. (2014)](https://arxiv.org/abs/1409.0473)"
      ],
      "metadata": {
        "id": "MlQQiuKidVzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Теория"
      ],
      "metadata": {
        "id": "SHpgueowsRdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN и проблема длинных предложений**\n",
        "\n",
        " Вектор фиксированной длины размера окна n ->\n",
        "\n",
        " -> не можем обработать длинные последовательности,\n",
        "\n",
        " -> теряем информацию о рекурсивных конструкциях естественного языка,\n",
        "\n",
        " -> градиент взрывается или исчезает\n",
        "\n",
        "Решение: **механизм внимания**. Первоначально итеративный:\n",
        "\n",
        "1. Оценка выравнивания `a(s_t-1, h_i)`, где\n",
        "  1. `h_i` - скрытое состояние кодера (текущее состояние векторного пространства эмбеддингов, которое построила наша модель для входного текста; например, эмбеддинг для `меня зовут Джон`),\n",
        "  2. `s_t-1` - выходные данные декодера на предыдущем шаге вычислений `t-1` (то, что модель расшифровала на основе предыдущего скрытого состояния; например, декодер расшифровал вектор `меня зовут` и получилось `my name is`),\n",
        "  3. `a` - это оценка связи между *текущими* входными и *текущими* выходными данными на шаге `t` (итак, нам нужна нейросеть, которая расчитает `a(\"my name is\", \"меня зовут Джон\")`, чтобы оценить силу связи между декодированными выходными данными `John` и векторным представлением `меня зовут Иван` на основе предыдущего шага декодера `t-1`). Чем выше связь, тем выше оценка.\n",
        "2. Текущая оценка `a` (для слова `John`) преобразовывается к виду весов `w_a`, чтобы их можно было использовать в качестве параметра. Применяем `softmax`, чтобы преобразовать оценки к виду коэффициентов от 0 до 1. Каждое слово в нашем словаре получит такой коэффициент.\n",
        "3. Вектор контекста `c_t` - это взвешенная сумма всех скрытых состояний кодера `v(\"меня\" * w_a_t-2) + v(\"меня зовут\" * w_a_t-1) + v(\"меня зовут Джон\" * w_a_t)`; этот вектор мы будем скармливать декодеру на текущем шаге `t`, чтобы получился вектор внимания для слова `John`.\n",
        "\n",
        "Как это выглядит **в коде**? В коде мы сразу создаем матрицу внимания для всего датасета, без необходимости в последовательном, итерационном расчете с помощью трех матриц: `queries`, `keys`, `values`.\n",
        "\n",
        "1. Оценка выравнивания: `k_i*q`, где\n",
        "  1. `k_i` - база данных ключей (keys), список закодированных входных токенов (`[v\"меня\", v\"зовут\", v\"Джон\"]`),\n",
        "  2. `q` - вектор текущего шага, для которого мы строим представление с помощью механизма внимания, наш `John`. На этом месте последовательно окажется каждый из векторов нашего декодера: `q_1: my`; `q_2: name`; `q_3: is`; `q_4: John`. При этом база `k_i` меняться не будет. Таким образом, у нас получится 4 матрицы `a_my`, `a_name`, `a_is`, `a_John`, в каждой из которых хранится оценка связи между `q_n` и каждым из элементов `k_i`. Например: `{John: меня, 12}; {John: зовут, 10}; {John: Джон, 78}`.\n",
        "2. `a = softmax(k_i*q)`, преобразовали все оценки к виду коэффициентов от 0 до 1.\n",
        "3. `a*v_k`, где `v_k` - вектор ключа (совпадает с `k_i`, но для удобства расчетов хранится в отдельной базе данных); итак, получается вектор внимания - взвешенная сумма `attention_John = ({v\"меня\" * 0.2} + {v\"зовут\" * 0.2}; {v\"Джон\" * 0.6})`.\n",
        "\n",
        "**Итого**: каждое слово в нашем корпусе Y представлено его силой связи с *каждым* из слова корпуса X.\n"
      ],
      "metadata": {
        "id": "VJ9fD800dhZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Механизм внимания с нуля с помощью NumPy"
      ],
      "metadata": {
        "id": "JuKGl61csUO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# датасет\n",
        "\n",
        "source_sentences = [\"My name is John\", \"His name is John\", \"Her name is Jane\", \"My name is Jane\"]\n",
        "target_sentences = [\"Меня зовут Джон\", \"Его зовут Джон\", \"Ее зовут Джейн\", \"Меня зовут Джейн\"]"
      ],
      "metadata": {
        "id": "bO3G483ouPbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# токенизация\n",
        "\n",
        "import re\n",
        "\n",
        "def tokenize(sentence):\n",
        "    tokens = sentence.lower().split()\n",
        "    return [re.sub(r'[^\\w\\s]', '', token) for token in tokens]\n",
        "\n",
        "source_tokens, target_tokens = [tokenize(sent) for sent in source_sentences], [tokenize(sent) for sent in target_sentences]\n",
        "\n",
        "print(\"Исходные токены:\\n\", source_tokens)\n",
        "print()\n",
        "print(\"Целевые токены:\\n\", target_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlafiJmY0sPm",
        "outputId": "daae36dd-255f-4f42-912f-d6aa2e211470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходные токены:\n",
            " [['my', 'name', 'is', 'john'], ['his', 'name', 'is', 'john'], ['her', 'name', 'is', 'jane'], ['my', 'name', 'is', 'jane']]\n",
            "\n",
            "Целевые токены:\n",
            " [['меня', 'зовут', 'джон'], ['его', 'зовут', 'джон'], ['ее', 'зовут', 'джейн'], ['меня', 'зовут', 'джейн']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# мешок слов\n",
        "\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "def bag_of_words(tokenized_sentences):\n",
        "\n",
        "  print(\"Корпус:\\n\", tokenized_sentences)\n",
        "\n",
        "  # словарь уникальных словоформ\n",
        "  words = [word for sentence in tokenized_sentences for word in sentence]\n",
        "  unique_words = sorted(set(words))\n",
        "  print(\"\\nУникальные словоформы корпуса:\\n\", unique_words)\n",
        "\n",
        "  print(\"\\nМешок слов:\")\n",
        "  matrix = []\n",
        "\n",
        "  for word in unique_words:\n",
        "    temp = []\n",
        "    for sent in tokenized_sentences:\n",
        "      temp.append(1 if word in sent else 0)\n",
        "    matrix.append(temp)\n",
        "    print({word: temp})\n",
        "\n",
        "  return np.array(matrix)\n",
        "\n",
        "bow_source, bow_target = bag_of_words(source_tokens), bag_of_words(target_tokens)\n",
        "\n",
        "print(\"\\nРезультат для целевого корпуса (K, V):\\n\", bow_source)\n",
        "print(\"\\nРезультат для исходного корпуса (Q):\\n\", bow_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpJ34MO_uOHM",
        "outputId": "6ab5c5c1-43a9-4c11-ec11-1197b1a5b530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Корпус:\n",
            " [['my', 'name', 'is', 'john'], ['his', 'name', 'is', 'john'], ['her', 'name', 'is', 'jane'], ['my', 'name', 'is', 'jane']]\n",
            "\n",
            "Уникальные словоформы корпуса:\n",
            " ['her', 'his', 'is', 'jane', 'john', 'my', 'name']\n",
            "\n",
            "Мешок слов:\n",
            "{'her': [0, 0, 1, 0]}\n",
            "{'his': [0, 1, 0, 0]}\n",
            "{'is': [1, 1, 1, 1]}\n",
            "{'jane': [0, 0, 1, 1]}\n",
            "{'john': [1, 1, 0, 0]}\n",
            "{'my': [1, 0, 0, 1]}\n",
            "{'name': [1, 1, 1, 1]}\n",
            "Корпус:\n",
            " [['меня', 'зовут', 'джон'], ['его', 'зовут', 'джон'], ['ее', 'зовут', 'джейн'], ['меня', 'зовут', 'джейн']]\n",
            "\n",
            "Уникальные словоформы корпуса:\n",
            " ['джейн', 'джон', 'его', 'ее', 'зовут', 'меня']\n",
            "\n",
            "Мешок слов:\n",
            "{'джейн': [0, 0, 1, 1]}\n",
            "{'джон': [1, 1, 0, 0]}\n",
            "{'его': [0, 1, 0, 0]}\n",
            "{'ее': [0, 0, 1, 0]}\n",
            "{'зовут': [1, 1, 1, 1]}\n",
            "{'меня': [1, 0, 0, 1]}\n",
            "\n",
            "Результат для целевого корпуса (K, V):\n",
            " [[0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [1 1 1 1]\n",
            " [0 0 1 1]\n",
            " [1 1 0 0]\n",
            " [1 0 0 1]\n",
            " [1 1 1 1]]\n",
            "\n",
            "Результат для исходного корпуса (Q):\n",
            " [[0 0 1 1]\n",
            " [1 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [1 1 1 1]\n",
            " [1 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# случайные веса (в идеале, в этой ячейке мы используем метод обратного распространения ошибки для расчета весов)\n",
        "# 4 - размерность вектора, равна количеству текстов в параллельном корпусе (здесь!)\n",
        "\n",
        "from numpy import random\n",
        "\n",
        "random.seed(2024)\n",
        "\n",
        "W_Q = random.randint(2, size=(4, 4))\n",
        "W_K = random.randint(2, size=(4, 4))\n",
        "W_V = random.randint(2, size=(4, 4))\n",
        "\n",
        "W_Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJLcFqMILAYq",
        "outputId": "6bda12aa-c455-43ab-feed-8fa32aff1592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0],\n",
              "       [1, 0, 0, 1],\n",
              "       [1, 1, 1, 0],\n",
              "       [1, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Метод обратного распространения ошибки (backpropagation)** - метод вычисления градиента для обновления весов нейронной сети.\n",
        "\n",
        "1. forward pass / propagation: входные данные передаются нейронной сети, чтобы получить предсказания на выходе\n",
        "2. backward pass: вычисляем градиент функции потерь и обновляем веса нейросети\n",
        "\n",
        "Псевдокод процесса обучения:\n",
        "\n",
        "```\n",
        "for epoch in epochs:    \n",
        "    \n",
        "    1. feedforward propagation\n",
        "    # скрытый слой\n",
        "    result_n-1 = func(x_train, weight_n-1)\n",
        "    activated_n-1 = activation_func(result_n-1)\n",
        "\n",
        "    # выходной слой\n",
        "    result_n = func(activated_n-1, weight_n)\n",
        "    activated_n = activation_func(result_n)\n",
        "    \n",
        "    2. вычисление ошибки\n",
        "    mean_squared_error(activated_n, y_train)\n",
        "    metric_score(activated_n, y_train)\n",
        "    \n",
        "    3. backpropagation\n",
        "    delta_weight_n-1\n",
        "    delta_weight_n\n",
        "    \n",
        "    4. обновление весов\n",
        "    learning_rate * weight_n_update\n",
        "    learning_rate * weight_n-1_update\n",
        "```"
      ],
      "metadata": {
        "id": "2Y2gmsV-ZrOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# умножение матриц: взвешиваем каждый эмбеддинг\n",
        "\n",
        "query_1 = bow_target[0] @ W_Q\n",
        "key_1 = bow_source[0] @ W_K\n",
        "value_1 = bow_source[0] @ W_V\n",
        "\n",
        "query_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8306HoAVMhF7",
        "outputId": "568dcd29-2e97-4ced-cffa-45cfd56bd292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# матричные операции позволяют делать это не итеративно, но для корпуса целиком\n",
        "\n",
        "Q = bow_target @ W_Q\n",
        "K = bow_source @ W_K\n",
        "V = bow_source @ W_V\n",
        "\n",
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdQknKNuLKXR",
        "outputId": "5886b60f-35fd-4fc2-dc8f-8f91e859554b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 1, 1, 0],\n",
              "       [1, 0, 0, 1],\n",
              "       [1, 0, 0, 1],\n",
              "       [1, 1, 1, 0],\n",
              "       [3, 1, 1, 1],\n",
              "       [1, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь можно получить скор выравнивания\n",
        "\n",
        "from numpy import dot\n",
        "\n",
        "scores = np.array([dot(Q[0], K[0]), dot(Q[0], K[1]), dot(Q[0], K[1]), dot(Q[0], K[2])])\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "layl5EnWOAO_",
        "outputId": "aa94e42d-dc38-464c-8276-41c01fab9481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4,  3,  3, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# для вычислений матрицу ключей нужно транспонировать\n",
        "\n",
        "scores = Q @ K.transpose()\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ype_on6hO4ud",
        "outputId": "76b0304e-cc17-4dc2-b38c-434a9232d8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  3, 13,  7,  6,  6, 13],\n",
              "       [ 1,  1,  4,  2,  2,  2,  4],\n",
              "       [ 1,  1,  4,  2,  2,  2,  4],\n",
              "       [ 3,  2,  9,  5,  4,  4,  9],\n",
              "       [ 5,  4, 17,  9,  8,  8, 17],\n",
              "       [ 1,  1,  4,  2,  2,  2,  4]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Транспонирование матрицы** - замена строк матрицы на ее столбцы, и наоборот. Иногда нам нужно транспонировать матрицу перед операцией умножения, чтобы структуры матриц были сопоставимы, а умножение возможным. Иногда транспонирование требуется, чтобы получить больше информации о том, что в ней хранится."
      ],
      "metadata": {
        "id": "YocdWwOOZfS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# эти значения нужно нормализовать; применим softmax\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "a = softmax(scores)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fft57kCpPS4k",
        "outputId": "2c9aa321-c7a0-4deb-f9fa-7875114fb8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.10909001e-06, 4.08011413e-07, 8.98704943e-03, 2.22766683e-05,\n",
              "        8.19512830e-06, 8.19512830e-06, 8.98704943e-03],\n",
              "       [5.52183401e-08, 5.52183401e-08, 1.10909001e-06, 1.50099011e-07,\n",
              "        1.50099011e-07, 1.50099011e-07, 1.10909001e-06],\n",
              "       [5.52183401e-08, 5.52183401e-08, 1.10909001e-06, 1.50099011e-07,\n",
              "        1.50099011e-07, 1.50099011e-07, 1.10909001e-06],\n",
              "       [4.08011413e-07, 1.50099011e-07, 1.64603552e-04, 3.01481922e-06,\n",
              "        1.10909001e-06, 1.10909001e-06, 1.64603552e-04],\n",
              "       [3.01481922e-06, 1.10909001e-06, 4.90676273e-01, 1.64603552e-04,\n",
              "        6.05542627e-05, 6.05542627e-05, 4.90676273e-01],\n",
              "       [5.52183401e-08, 5.52183401e-08, 1.10909001e-06, 1.50099011e-07,\n",
              "        1.50099011e-07, 1.50099011e-07, 1.10909001e-06]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь мы можем вычислить внимание: взвешенную сумму значений\n",
        "\n",
        "A = a @ V\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFnC-PLaPxKE",
        "outputId": "372bc706-ea3f-4e56-db77-58a9ce6f4515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.59950598e-02, 5.39925444e-02, 3.59872727e-02, 5.39847573e-02],\n",
              "       [5.03675608e-06, 7.46025345e-06, 4.94187541e-06, 7.36537278e-06],\n",
              "       [5.03675608e-06, 7.46025345e-06, 4.94187541e-06, 7.36537278e-06],\n",
              "       [6.64756297e-04, 9.97386232e-04, 6.63797306e-04, 9.96427241e-04],\n",
              "       [1.96305136e+00, 2.94457152e+00, 1.96299191e+00, 2.94451208e+00],\n",
              "       [5.03675608e-06, 7.46025345e-06, 4.94187541e-06, 7.36537278e-06]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words =  ['джейн', 'джон', 'его', 'ее', 'зовут', 'меня']\n",
        "\n",
        "for i in range(len(unique_words)):\n",
        "  print(unique_words[i], A[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MxOE7PvS-5u",
        "outputId": "7a5be1bd-e15b-4043-a3c3-b27281a703ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "джейн [0.03599506 0.05399254 0.03598727 0.05398476]\n",
            "джон [5.03675608e-06 7.46025345e-06 4.94187541e-06 7.36537278e-06]\n",
            "его [5.03675608e-06 7.46025345e-06 4.94187541e-06 7.36537278e-06]\n",
            "ее [0.00066476 0.00099739 0.0006638  0.00099643]\n",
            "зовут [1.96305136 2.94457152 1.96299191 2.94451208]\n",
            "меня [5.03675608e-06 7.46025345e-06 4.94187541e-06 7.36537278e-06]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(source_tokens[0])\n",
        "\n",
        "sorted([elem[0] for elem in A]) # джон меня его ... (результат со случайным распределением весов)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FVxzpKJTM2G",
        "outputId": "bbe67649-178a-450f-9d85-2a55786c2250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'name', 'is', 'john']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.036756079674562e-06,\n",
              " 5.036756079674562e-06,\n",
              " 5.036756079674562e-06,\n",
              " 0.0006647562973232436,\n",
              " 0.03599505976974601,\n",
              " 1.963051358687789]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# как автоматизировать поиск токенов с наибольшим весом?\n",
        "np.argmax([0, 1, 3, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9S9xtPtST9b",
        "outputId": "de348905-456c-49e5-fd46-686eeddbf118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, SimpleRNN, Attention\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(units=3))\n",
        "model.add(Dense(units=1))\n",
        "model.compile()\n",
        "model.build(input_shape=(2,2,2))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HCbiqV0pKXPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225e654b-e082-40a8-a9b5-207a4a2f10c0"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_25 (SimpleRNN)   (2, 3)                    18        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (2, 1)                    4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22 (88.00 Byte)\n",
            "Trainable params: 22 (88.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}