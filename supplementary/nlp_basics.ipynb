{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk371iFkt5yQWzztShF98s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/compling/blob/main/supplementary/nlp_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основные операции обработки естественного языка"
      ],
      "metadata": {
        "id": "24mOhpO8ttqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обзор инструментов из популярных библиотек для обработки текстов `NLTK` и `Spacy`"
      ],
      "metadata": {
        "id": "zLO4ZrtcuNNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "Cql0y44Iv2T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем с импорта библиотек.\n",
        "\n",
        "Обратите внимание: для работы NLTK нужно дополнительно загрузить ресурсы."
      ],
      "metadata": {
        "id": "OJB08tXavEph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # ресурс для токенизации\n",
        "nltk.download('wordnet') # ресурс для лемматизации\n",
        "nltk.download('stopwords') # ресурс для извлечения списка стоп-слов\n",
        "\n",
        "import spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6lv6cZKu_ZY",
        "outputId": "b562c741-e7e1-4d06-fbde-ca8c44fec420"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенизация"
      ],
      "metadata": {
        "id": "8IxxlS9Ft697"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инструмент `word_tokenize` из библиотеки `NLTK`"
      ],
      "metadata": {
        "id": "3M84fRLjuDak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AteyZfYfkdk0",
        "outputId": "28707f3c-a873-4ff2-be7e-89cb9ec95dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наш текст: The quick brown fox jumps over the lazy dog\n",
            "Токены: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# образец текста\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# загружаем текст в токенизатор\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "print(\"Наш текст:\", text)\n",
        "print(\"Токены:\", tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация с помощью `spacy`"
      ],
      "metadata": {
        "id": "Kk5P71ewu1QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем модель Spacy для английского языка\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# образец текста\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# обработка текста (создаем объект spacy)\n",
        "doc = nlp(text)\n",
        "\n",
        "# извлечение токенов\n",
        "tokens = [token.text for token in doc]\n",
        "\n",
        "print(\"Наш текст:\", text)\n",
        "print(\"Токены:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkhUq1lokfIG",
        "outputId": "56843ecd-4cad-4991-b3b0-ae1378846386"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наш текст: The quick brown fox jumps over the lazy dog\n",
            "Токены: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизация"
      ],
      "metadata": {
        "id": "VrQZ66KJvrnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инструмент `WordNetLemmatizer` из библиотеки `NLTK`"
      ],
      "metadata": {
        "id": "31mt37drwBdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# образец текста\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# токенизация\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# лемматизация: инициализация WordNetLemmatizer и извлечение лемм\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_text = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "print(\"Наш текст:\", text)\n",
        "print(\"Леммы:\", lemmatized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So0NiIfWlcOm",
        "outputId": "2efa2be1-aa0d-45c9-adb1-ebd0cfb8ed73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наш текст: The quick brown fox jumps over the lazy dog\n",
            "Леммы: ['The', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лемматизация с помощью `spacy`"
      ],
      "metadata": {
        "id": "CSYsd5GGwCuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем модель Spacy для английского языка\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# образец текста\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# обработка текста (создаем объект spacy)\n",
        "doc = nlp(text)\n",
        "\n",
        "# извлечение лемм\n",
        "lemmatized_text = [token.lemma_ for token in doc]\n",
        "\n",
        "print(\"Наш текст:\", text)\n",
        "print(\"Леммы:\", lemmatized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR_RSnBxlygp",
        "outputId": "f2a8833d-b751-4418-84e9-1b6f664c598e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наш текст: The quick brown fox jumps over the lazy dog\n",
            "Леммы: ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Удаление стоп-слов"
      ],
      "metadata": {
        "id": "YX1ym2lRvy_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инструмент `word_tokenize` из библиотеки `NLTK`"
      ],
      "metadata": {
        "id": "m5oqDvptwFR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# образец текста\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# токенизация\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# загружаем стоп-слова\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# удаляем стоп-слова\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "print(\"Наш текст:\", text)\n",
        "print(\"Токены без стоп-слов:\", filtered_tokens)"
      ],
      "metadata": {
        "id": "NOzasVrenISU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37e032a-4a44-4743-c7cf-69aa6a1c6322"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наш текст: The quick brown fox jumps over the lazy dog\n",
            "Токены без стоп-слов: ['quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лемматизация с помощью `spacy`"
      ],
      "metadata": {
        "id": "xnNeJvmcxVui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем модель Spacy для английского языка\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# образец текста\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# обработка текста (создаем объект spacy)\n",
        "doc = nlp(text)\n",
        "\n",
        "# фильтрация от стоп-слов\n",
        "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "print(\"Наш текст:\", text)\n",
        "print(\"Токены без стоп-слов:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26B1XvoawGyy",
        "outputId": "14bf039c-9986-4c23-d8f1-da02c275082c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наш текст: The quick brown fox jumps over the lazy dog\n",
            "Токены без стоп-слов: ['quick', 'brown', 'fox', 'jumps', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Курс \"Компьютерная лингвистика\" | НИУ ВШЭ Санкт-Петербург\n",
        "2024 (c) В.И. Фирсанова\n",
        "```"
      ],
      "metadata": {
        "id": "GJ5ULQrHy9Ge"
      }
    }
  ]
}